{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATS Tracker MilvusDB Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType, utility, AnnSearchRequest, WeightedRanker\n",
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "milvusdb_uri=\"../db/milvus/ats_tracker.db\"\n",
    "resumes_uri=\"../data/master_data/resumes/v1.0/\"\n",
    "resumes_zipped_metadata_uri=\"../data/master_data/resumes/v1.0/resumes_metadata.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(pdf_path:str)->str:\n",
    "    \"\"\"reads pdf and return them as a string\"\"\"\n",
    "    reader=PdfReader(pdf_path)\n",
    "    txt=\"\"\n",
    "    for page in reader.pages:\n",
    "        txt+=\"\\n\"+page.extract_text()        \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5fafb602954bcb872da850edbad8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume size:  2484\n"
     ]
    }
   ],
   "source": [
    "resumes=[]\n",
    "for (root, dirs, files) in tqdm(os.walk(resumes_uri)):\n",
    "    for f in files:\n",
    "        if \".pdf\" in f:         \n",
    "            resume_domain=os.path.basename(os.path.normpath(root))\n",
    "            resume_id=f.replace(\".pdf\", \"\")\n",
    "            resume_uri=os.path.join(root, f)            \n",
    "            resume=read_pdf(resume_uri)\n",
    "            \n",
    "            resumes.append([resume_id, resume_domain, resume_uri, resume])\n",
    "\n",
    "print(\"resume size: \", len(resumes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_id</th>\n",
       "      <th>resume_domain</th>\n",
       "      <th>resume_uri</th>\n",
       "      <th>resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10554236</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>../data/master_data/resumes/v1.0/ACCOUNTANT/10...</td>\n",
       "      <td>\\nACCOUNTANT\\nSummary\\nFinancial Accountant sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10674770</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>../data/master_data/resumes/v1.0/ACCOUNTANT/10...</td>\n",
       "      <td>\\nSTAFF ACCOUNTANT\\nSummary\\nHighly analytical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11163645</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>../data/master_data/resumes/v1.0/ACCOUNTANT/11...</td>\n",
       "      <td>\\nACCOUNTANT\\nProfessional Summary\\nTo obtain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11759079</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>../data/master_data/resumes/v1.0/ACCOUNTANT/11...</td>\n",
       "      <td>\\nSENIOR ACCOUNTANT\\nExperience\\nCompany Name\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12065211</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>../data/master_data/resumes/v1.0/ACCOUNTANT/12...</td>\n",
       "      <td>\\nSENIOR ACCOUNTANT\\nProfessional Summary\\nSen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resume_id resume_domain                                         resume_uri  \\\n",
       "0  10554236    ACCOUNTANT  ../data/master_data/resumes/v1.0/ACCOUNTANT/10...   \n",
       "1  10674770    ACCOUNTANT  ../data/master_data/resumes/v1.0/ACCOUNTANT/10...   \n",
       "2  11163645    ACCOUNTANT  ../data/master_data/resumes/v1.0/ACCOUNTANT/11...   \n",
       "3  11759079    ACCOUNTANT  ../data/master_data/resumes/v1.0/ACCOUNTANT/11...   \n",
       "4  12065211    ACCOUNTANT  ../data/master_data/resumes/v1.0/ACCOUNTANT/12...   \n",
       "\n",
       "                                              resume  \n",
       "0  \\nACCOUNTANT\\nSummary\\nFinancial Accountant sp...  \n",
       "1  \\nSTAFF ACCOUNTANT\\nSummary\\nHighly analytical...  \n",
       "2  \\nACCOUNTANT\\nProfessional Summary\\nTo obtain ...  \n",
       "3  \\nSENIOR ACCOUNTANT\\nExperience\\nCompany Name\\...  \n",
       "4  \\nSENIOR ACCOUNTANT\\nProfessional Summary\\nSen...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resumes=pd.DataFrame(resumes, columns=[\"resume_id\", \"resume_domain\", \"resume_uri\", \"resume\"])\n",
    "df_resumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumes.to_csv(\"../data/processed_data/resumes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BGE-M3 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970e73951b1749dca55a55b19d48bd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# please set the use_fp16 to False when you are using cpu.\n",
    "# by default the return options is:\n",
    "#  return_dense True\n",
    "#  return_sparse True\n",
    "#  return_colbert_vecs False \n",
    "bge_m3 = BGEM3EmbeddingFunction(\n",
    "    model_name='BAAI/bge-m3',   # specify the model name\n",
    "    device='cpu',               # specify the device to use, e.g., 'cpu' or 'cuda:0'\n",
    "    use_fp16=False              # specify whether to use fp16. Set to `False` if `device` is `cpu`.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_documents(docs):\n",
    "    \"\"\"BGE-M3 returns both dense and sparse encodings\"\"\"\n",
    "    embeddings = bge_m3.encode_documents(docs)\n",
    "    return embeddings[\"dense\"], list(embeddings[\"sparse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MilvusDB Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to MilvusDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(uri=milvusdb_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Milvus Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_dim=1024 # len(dense_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define field names and their data types\n",
    "pk_field = \"doc_id\"\n",
    "id_field = \"id\"\n",
    "domain_field = \"domain\"\n",
    "dense_field = \"dense_vector\"\n",
    "sparse_field = \"sparse_vector\"\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=pk_field, dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100),\n",
    "    FieldSchema(name=id_field, dtype=DataType.VARCHAR, max_length=100),\n",
    "    FieldSchema(name=domain_field, dtype=DataType.VARCHAR, max_length=200),\n",
    "    FieldSchema(name=dense_field, dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n",
    "    FieldSchema(name=sparse_field, dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "]\n",
    "\n",
    "# create a collection with the defined schema\n",
    "schema = CollectionSchema(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create milvus collection\n",
    "collection_name = \"ats_tracker_resumes_collection\"\n",
    "\n",
    "if utility.has_collection(collection_name):\n",
    "    Collection(collection_name).drop()\n",
    "\n",
    "collection = Collection(collection_name, schema, consistency_level=\"Strong\")\n",
    "\n",
    "# To make vector search efficient, we need to create indices for the vector fields\n",
    "sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "collection.create_index(sparse_field, sparse_index)\n",
    "\n",
    "dense_index = {\"index_type\": \"AUTOINDEX\", \"metric_type\": \"IP\"}\n",
    "collection.create_index(dense_field, dense_index)\n",
    "\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2d42586f2445a28f318fe2e47ce047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# define batch size\n",
    "batch_size=20\n",
    "\n",
    "def process_batch(batch):\n",
    "    entities=[]\n",
    "\n",
    "    for _, row in batch.iterrows():\n",
    "        id=row[\"resume_id\"]\n",
    "        domain=row[\"resume_domain\"]\n",
    "        dense_embeds, sparse_embeds=encode_documents([row[\"resume\"]])\n",
    "\n",
    "        # convert csr matrix to dictionary\n",
    "        row_index=0\n",
    "        sparse_dictionary={idx: val for idx, val in zip(sparse_embeds[row_index].indices, sparse_embeds[row_index].data)}\n",
    "\n",
    "        # create entity with correct field names\n",
    "        entity={\n",
    "            id_field: id,\n",
    "            domain_field: domain,\n",
    "            dense_field: dense_embeds[0],\n",
    "            sparse_field: sparse_dictionary,\n",
    "        }\n",
    "\n",
    "        entities.append(entity)\n",
    "\n",
    "    # upsert the batch of entities into Milvus\n",
    "    if len(entities) > 0:\n",
    "        resp = collection.insert(entities)\n",
    "\n",
    "    return resp\n",
    "\n",
    "def divide_chunks(df, batch_size):\n",
    "    # yield successive n-sized chunks from the dataframe\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        yield df.iloc[i:i + batch_size]\n",
    "\n",
    "# process and insert the df_resumes in batches\n",
    "for batch in tqdm(divide_chunks(df_resumes, batch_size)):\n",
    "    # process each batch\n",
    "    resp=process_batch(batch)\n",
    "\n",
    "    # flush to ensure data is persisted\n",
    "    collection.flush()\n",
    "\n",
    "# load the collection into memory for querying\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumes Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumes_filter(\n",
    "    collection,\n",
    "    query_dense_embedding,\n",
    "    query_sparse_embedding,\n",
    "    sparse_weight=1.0,\n",
    "    dense_weight=1.0,\n",
    "    limit=10,\n",
    "):\n",
    "    dense_search_params={\"metric_type\": \"IP\", \"params\": {}}\n",
    "    dense_req=AnnSearchRequest(\n",
    "        [query_dense_embedding], \"dense_vector\", dense_search_params, limit=limit\n",
    "    )\n",
    "    sparse_search_params={\"metric_type\": \"IP\", \"params\": {}}\n",
    "    sparse_req=AnnSearchRequest(\n",
    "        [query_sparse_embedding], \"sparse_vector\", sparse_search_params, limit=limit\n",
    "    )\n",
    "    rerank=WeightedRanker(sparse_weight, dense_weight)\n",
    "    resp=collection.hybrid_search(\n",
    "        [sparse_req, dense_req], rerank=rerank, limit=limit, output_fields=[\"id\"]\n",
    "    )[0]\n",
    "    return [hit.get(\"id\") for hit in resp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"python developer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes search results:  ['20674668', '71767359', '62994611', '26503829', '12632728', '26746496', '14771530', '16186411', '19557384', '12144825']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dense_query_embeds, sparse_query_embeds=encode_documents([query])\n",
    "\n",
    "# convert csr matrix to dictionary\n",
    "row_index=0\n",
    "sparse_dictionary={idx: val for idx, val in zip(sparse_query_embeds[row_index].indices, sparse_query_embeds[row_index].data)}\n",
    "\n",
    "results=resumes_filter(\n",
    "    collection,\n",
    "    dense_query_embeds[0],\n",
    "    sparse_dictionary,\n",
    "    sparse_weight=0.5,\n",
    "    dense_weight=0.5,\n",
    ")\n",
    "\n",
    "print(\"Resumes search results: \", results)\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
